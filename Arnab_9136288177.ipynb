{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKIguexuedBh"
   },
   "outputs": [],
   "source": [
    "import os,json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from string import punctuation\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras import utils\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input , Dense , LSTM,GlobalAveragePooling1D,GlobalMaxPooling1D,Bidirectional,LSTM,Conv1D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RClJ8G9zwWWd"
   },
   "outputs": [],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RYxjPGK1JVs"
   },
   "source": [
    "Reading the JSON files and extracting  ***jd_information*** and ***description*** and storing it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-l18mcXxxLjd"
   },
   "outputs": [],
   "source": [
    "json_files_path = 'data/docs/'\n",
    "json_files = [pos_json for pos_json in os.listdir(json_files_path) if pos_json.endswith('.json')]\n",
    "\n",
    "job_desc = pd.DataFrame(columns=['Description', 'Document ID'])\n",
    "for index, js in enumerate(json_files):\n",
    "    with open(os.path.join(json_files_path, js)) as json_file:\n",
    "        json_data = json.load(json_file)        \n",
    "        desc = json_data['jd_information']['description']\n",
    "        id= json_data['_id']\n",
    "        job_desc.loc[index] = [desc ,id]\n",
    "job_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oOD2BlyA2bm0"
   },
   "source": [
    "Reading Job Department file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nP6_Mf9pxjhZ",
    "outputId": "521be04c-15cd-4040-cb4c-e003c174064c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1162, 2)"
      ]
     },
     "execution_count": 253,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_dept=pd.read_csv('data/document_departments.csv')\n",
    "job_dept.head()\n",
    "job_dept[\"Document ID\"]=job_dept[\"Document ID\"].astype(str)\n",
    "job_dept.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gTWaIHyE39ij",
    "outputId": "96703a37-2df0-431f-b068-5256747638fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Document ID', 'Department'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(job_dept.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmaxg9MZ3Jrn"
   },
   "source": [
    "Joining the two dataframe on Document ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4N2Ku9CyJxj"
   },
   "outputs": [],
   "source": [
    "job_final = job_desc.merge(job_dept, on=\"Document ID\", how = 'inner')\n",
    "job_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JcMEssYO5DZT"
   },
   "source": [
    "\n",
    "Exploratory Data Analysis ( EDA ) of the Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lkhlvu87zJQE"
   },
   "outputs": [],
   "source": [
    "\n",
    "diff_words = job_final.groupby('Department').filter(lambda x: len(x) > 15)\n",
    "words = diff_words['Department'].value_counts().index.tolist()\n",
    "fig, ax = plt.subplots(figsize = (20, 10))\n",
    "sns.countplot(x = diff_words['Department'], order = words, ax = ax)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIDWB9dN-2Rr"
   },
   "source": [
    "Checking if description column has some text or it is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-msXWjpf9waY"
   },
   "outputs": [],
   "source": [
    "job_final['Description'] == \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBAjxkUm_GVl"
   },
   "source": [
    "Dropping empty description rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pRjnXbwo_EN2",
    "outputId": "a0d99592-79e8-4351-db7b-48fce2ea7f62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(745, 3)"
      ]
     },
     "execution_count": 258,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_final = job_final[job_final.Description != '']\n",
    "job_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16BwF9DXCoMj"
   },
   "source": [
    "Preprocessing the Text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MSLAo95KCs5r"
   },
   "source": [
    "Removing contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcNiZYmECqRh"
   },
   "outputs": [],
   "source": [
    "def remove_contraction(phrase):\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1m3cfWYDHNb"
   },
   "outputs": [],
   "source": [
    "final = job_final.apply(lambda row: remove_contraction(row['Description']), axis=1)\n",
    "job_final['Description'] = final\n",
    "job_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nz-_YYo3Rv62"
   },
   "source": [
    "Removing numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DzfgpzrGESdm"
   },
   "outputs": [],
   "source": [
    "\n",
    "punctuations=string.punctuation\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "job_final['Description']=job_final['Description'].apply(lambda x:remove_punct(x))\n",
    "job_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FsnDJwdlR7sp"
   },
   "source": [
    "Tokenizing the description and storing it in tokenized_description column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y2eoTJFiEqjG"
   },
   "outputs": [],
   "source": [
    "job_final['tokenized_description']=job_final.apply(lambda row:nltk.word_tokenize(row['Description']),axis=1 )\n",
    "job_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RBJBO0nMJbW"
   },
   "source": [
    "Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrtAQ8NHIJmW"
   },
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "job_final['tokenized_description']=job_final['tokenized_description'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWXKtcNWMmyD"
   },
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_DlTR0aMgix"
   },
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "def text_stemmer(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "job_final['tokenized_description']=job_final['tokenized_description'].apply(lambda x: text_stemmer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPqYa0tXMzYo"
   },
   "outputs": [],
   "source": [
    "job_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J3TNhf5cDZlj"
   },
   "source": [
    "checking for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBjWaKtuDXAm"
   },
   "outputs": [],
   "source": [
    "def class_pie_chart(labels):\n",
    "    class_map={}\n",
    "    for i in labels:\n",
    "        if str(i) not in class_map:\n",
    "            class_map[str(i)]=1\n",
    "        else:\n",
    "            class_map[str(i)]+=1\n",
    "    return class_map\n",
    "\n",
    "pie=class_pie_chart(job_final['Department'].values)\n",
    "print(pie)\n",
    "q=[i for i in pie.keys()]\n",
    "\n",
    "sizes = [i for i in pie.values()]\n",
    "colors = ['red', 'blue', 'yellow', 'green','purple']\n",
    "plt.pie(sizes, labels=q, colors=colors,\n",
    "         autopct='%1.1f%%',shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfJ08465ItSo"
   },
   "outputs": [],
   "source": [
    "class_map=pie\n",
    "for item in pie.keys():\n",
    "    if pie[item]<=5:\n",
    "        tempdf = job_final.loc[job_final['Department'] == item]\n",
    "        job_final = job_final.append(tempdf)\n",
    "        print(tempdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AiXYrHsjVj6n"
   },
   "source": [
    "Converting words to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1lK-GGSZcd6"
   },
   "outputs": [],
   "source": [
    "embedding_size=50\n",
    "input_length=100\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "file = open('glove.6B.50d.txt')\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coef = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coef\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8cghu56tp6d8"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(job_final.tokenized_description)\n",
    "X_data=tokenizer.texts_to_sequences(job_final.tokenized_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QCGnfATIqXIE",
    "outputId": "a4fc5809-36bd-44d1-b7b8-703b7b27623f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of tokens are 7183\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total length of tokens are ' +str( len(word_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHjF2DrybECw"
   },
   "source": [
    "Encoding the target class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tuw5aBeerNIl"
   },
   "outputs": [],
   "source": [
    "lbEnc=LabelEncoder()\n",
    "job_final['Department']=lbEnc.fit_transform(job_final['Department'])\n",
    "job_final['Department'].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2dhGVzldcYG"
   },
   "source": [
    "LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jf5HeKvyVAo"
   },
   "outputs": [],
   "source": [
    "max_features=200000\n",
    "max_sentence_len=75\n",
    "max_sentence_num=4\n",
    "embedding_size=50\n",
    "\n",
    "embedding_layer = Embedding(len(word_index)+1,embedding_size,input_length=max_sentence_len,trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "PDp79cThze3D",
    "outputId": "a996bc37-79c1-4454-ff9f-b470aefd3c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778, 75)\n",
      "(778, 27)\n"
     ]
    }
   ],
   "source": [
    "X = list(sequence.pad_sequences(X_data, maxlen=max_sentence_len))\n",
    "X=np.array(X)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "Y=utils.np_utils.to_categorical(job_final.Department)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJ0nkajUe7fy"
   },
   "source": [
    "Using SMOTE for over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67U24cMN-UR8"
   },
   "outputs": [],
   "source": [
    "def class_balancer(dataset,labels):\n",
    "    smote_X,smote_Y=SMOTE(k_neighbors=1).fit_resample(dataset,labels)\n",
    "    return smote_X,smote_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "zKRfm-GsFT0s",
    "outputId": "a8993a68-4b4d-43bc-dd10-9f79ae267728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6210, 75)\n",
      "(6210, 27)\n"
     ]
    }
   ],
   "source": [
    "smote_X,smote_Y=class_balancer(X,Y)\n",
    "\n",
    "print(smote_X.shape)\n",
    "print(smote_Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fsNa-Be2fRjt"
   },
   "source": [
    "Splitting the data into test-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Zoq_phEupC-"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(smote_X,smote_Y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9cBM4ui8dD1"
   },
   "outputs": [],
   "source": [
    "def classifier():\n",
    "    inp = Input(shape=(max_sentence_len,), dtype='int32')\n",
    "    x = embedding_layer(inp)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=False, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "    outp = Dense(27, activation=\"softmax\")(x)\n",
    "    BiLSTM = Model(inp, outp)\n",
    "    BiLSTM.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    print(BiLSTM.summary())\n",
    "    return BiLSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1053
    },
    "colab_type": "code",
    "id": "jwtIkX4Ef02v",
    "outputId": "aec524c2-0941-457f-fc56-14e03ee09714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 75, 50)            359200    \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 256)               183296    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 27)                6939      \n",
      "=================================================================\n",
      "Total params: 549,435\n",
      "Trainable params: 190,235\n",
      "Non-trainable params: 359,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4968 samples, validate on 1242 samples\n",
      "Epoch 1/20\n",
      "4968/4968 [==============================] - 33s 7ms/step - loss: 3.0249 - acc: 0.1439 - val_loss: 2.6034 - val_acc: 0.2834\n",
      "Epoch 2/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 2.3706 - acc: 0.3227 - val_loss: 2.1749 - val_acc: 0.3623\n",
      "Epoch 3/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 2.0515 - acc: 0.4088 - val_loss: 1.8644 - val_acc: 0.4839\n",
      "Epoch 4/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.8092 - acc: 0.4738 - val_loss: 1.6891 - val_acc: 0.5113\n",
      "Epoch 5/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.6470 - acc: 0.5151 - val_loss: 1.5382 - val_acc: 0.5531\n",
      "Epoch 6/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.4981 - acc: 0.5624 - val_loss: 1.4195 - val_acc: 0.5982\n",
      "Epoch 7/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.4502 - acc: 0.5620 - val_loss: 1.3302 - val_acc: 0.6006\n",
      "Epoch 8/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.3407 - acc: 0.5978 - val_loss: 1.2641 - val_acc: 0.6184\n",
      "Epoch 9/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.2535 - acc: 0.6167 - val_loss: 1.2026 - val_acc: 0.6208\n",
      "Epoch 10/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.2241 - acc: 0.6200 - val_loss: 1.1967 - val_acc: 0.6256\n",
      "Epoch 11/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.1736 - acc: 0.6361 - val_loss: 1.1949 - val_acc: 0.6095\n",
      "Epoch 12/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.1302 - acc: 0.6457 - val_loss: 1.1192 - val_acc: 0.6562\n",
      "Epoch 13/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.0996 - acc: 0.6570 - val_loss: 1.0875 - val_acc: 0.6554\n",
      "Epoch 14/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.0399 - acc: 0.6725 - val_loss: 1.0526 - val_acc: 0.6643\n",
      "Epoch 15/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.1055 - acc: 0.6506 - val_loss: 1.1322 - val_acc: 0.6377\n",
      "Epoch 16/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.0768 - acc: 0.6643 - val_loss: 1.0689 - val_acc: 0.6667\n",
      "Epoch 17/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.0351 - acc: 0.6757 - val_loss: 1.0178 - val_acc: 0.6659\n",
      "Epoch 18/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.0509 - acc: 0.6711 - val_loss: 1.0378 - val_acc: 0.6643\n",
      "Epoch 19/20\n",
      "4968/4968 [==============================] - 29s 6ms/step - loss: 1.0093 - acc: 0.6856 - val_loss: 0.9890 - val_acc: 0.6916\n",
      "Epoch 20/20\n",
      "4968/4968 [==============================] - 28s 6ms/step - loss: 0.9640 - acc: 0.6916 - val_loss: 0.9898 - val_acc: 0.6804\n"
     ]
    }
   ],
   "source": [
    "model=classifier()\n",
    "history=model.fit(X_train,Y_train,batch_size=64,epochs=20,validation_data=[X_test,Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "colab_type": "code",
    "id": "g6RegeHT9trK",
    "outputId": "59b8ab79-7c14-40b5-8068-fec7324bda85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.55      0.52        49\n",
      "           2       0.93      1.00      0.96        54\n",
      "           3       1.00      1.00      1.00        41\n",
      "           4       0.39      0.23      0.29        47\n",
      "           5       1.00      1.00      1.00        42\n",
      "           6       0.29      0.04      0.07        48\n",
      "           7       1.00      1.00      1.00        44\n",
      "           8       0.71      0.57      0.63        42\n",
      "           9       1.00      1.00      1.00        49\n",
      "          10       0.24      0.34      0.28        41\n",
      "          11       0.98      1.00      0.99        46\n",
      "          12       0.39      0.67      0.49        48\n",
      "          13       0.98      1.00      0.99        48\n",
      "          14       0.98      1.00      0.99        49\n",
      "          15       0.64      0.78      0.70        50\n",
      "          16       0.76      1.00      0.87        39\n",
      "          17       0.91      1.00      0.95        53\n",
      "          18       1.00      1.00      1.00        40\n",
      "          19       0.00      0.00      0.00        51\n",
      "          20       0.29      0.11      0.16        55\n",
      "          21       0.35      0.54      0.43        48\n",
      "          22       1.00      1.00      1.00        44\n",
      "          23       0.80      1.00      0.89        41\n",
      "          24       0.95      1.00      0.98        42\n",
      "          25       0.27      0.09      0.13        45\n",
      "          26       0.20      0.84      0.32        31\n",
      "          27       0.40      0.04      0.07        55\n",
      "\n",
      "    accuracy                           0.68      1242\n",
      "   macro avg       0.66      0.70      0.66      1242\n",
      "weighted avg       0.66      0.68      0.65      1242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model=np.argmax(model.predict(X_test),axis=1)\n",
    "trained_model=trained_model+1\n",
    "test=np.argmax(Y_test,axis=1)\n",
    "test=test+1\n",
    "\n",
    "print(classification_report(test, trained_model))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Arnab_9136288177.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
